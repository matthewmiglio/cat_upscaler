{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale_image(image,factor):\n",
    "    old_dims = image.shape\n",
    "    new_dims = [int(x * factor) for x in old_dims]\n",
    "    small_image= cv2.resize(image, (new_dims[1], new_dims[0]))\n",
    "    stretched_small_image = cv2.resize(small_image, (old_dims[1], old_dims[0]))\n",
    "    return stretched_small_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_side_by_side(lr, hr):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(lr)\n",
    "    plt.title('lr')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(hr)\n",
    "    plt.title('hr')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 5011 images in the folder\n",
      "(0 / 500) 0.415s per operation\n",
      "(10 / 500) 0.694s per operation\n",
      "(20 / 500) 0.382s per operation\n",
      "(30 / 500) 0.412s per operation\n",
      "(40 / 500) 0.329s per operation\n",
      "(50 / 500) 0.427s per operation\n",
      "(60 / 500) 0.539s per operation\n",
      "(70 / 500) 0.326s per operation\n",
      "(80 / 500) 0.314s per operation\n",
      "(90 / 500) 0.338s per operation\n",
      "(100 / 500) 0.388s per operation\n",
      "(110 / 500) 0.332s per operation\n",
      "(120 / 500) 0.419s per operation\n",
      "(130 / 500) 0.337s per operation\n",
      "(140 / 500) 0.417s per operation\n",
      "(150 / 500) 0.303s per operation\n",
      "(160 / 500) 0.973s per operation\n",
      "(170 / 500) 0.285s per operation\n",
      "(180 / 500) 0.318s per operation\n",
      "(190 / 500) 0.276s per operation\n",
      "(200 / 500) 0.039s per operation\n",
      "(210 / 500) 0.03s per operation\n",
      "(220 / 500) 0.027s per operation\n",
      "(230 / 500) 0.026s per operation\n",
      "(240 / 500) 0.023s per operation\n",
      "(250 / 500) 0.015s per operation\n",
      "(260 / 500) 0.033s per operation\n",
      "(270 / 500) 0.006s per operation\n",
      "(280 / 500) 0.019s per operation\n",
      "(290 / 500) 0.024s per operation\n",
      "(300 / 500) 0.027s per operation\n",
      "(310 / 500) 0.021s per operation\n",
      "(320 / 500) 0.036s per operation\n",
      "(330 / 500) 0.034s per operation\n",
      "(340 / 500) 0.023s per operation\n",
      "(350 / 500) 0.02s per operation\n",
      "(360 / 500) 0.021s per operation\n",
      "(370 / 500) 0.038s per operation\n",
      "(380 / 500) 0.041s per operation\n",
      "(390 / 500) 0.028s per operation\n",
      "(400 / 500) 0.029s per operation\n",
      "(410 / 500) 0.018s per operation\n",
      "(420 / 500) 0.119s per operation\n",
      "(430 / 500) 0.027s per operation\n",
      "(440 / 500) 0.026s per operation\n",
      "(450 / 500) 0.03s per operation\n",
      "(460 / 500) 0.018s per operation\n",
      "(470 / 500) 0.027s per operation\n",
      "(480 / 500) 0.027s per operation\n",
      "(490 / 500) 0.024s per operation\n"
     ]
    }
   ],
   "source": [
    "def make_datum(image_path, export_image_dims):\n",
    "    def calc_random_downscale_factors():\n",
    "        def valid_factors(factors):\n",
    "            # gap must not exceed 0.3\n",
    "            # first num must be smaller\n",
    "            # second num must be higher than 0.5\n",
    "\n",
    "            highest_gap = 0.5\n",
    "            min_value = 0.1\n",
    "\n",
    "            if any([x < min_value for x in factors]):\n",
    "                return False\n",
    "\n",
    "            if abs(factors[0] - factors[1]) > highest_gap:\n",
    "                return False\n",
    "            if factors[0] > factors[1]:\n",
    "                return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        while 1:\n",
    "            factors = [random.randint(0, 100) / 100 for _ in range(2)]\n",
    "            if valid_factors(factors):\n",
    "                return factors\n",
    "\n",
    "    random_factors = calc_random_downscale_factors()\n",
    "    image = cv2.imread(image_path)\n",
    "    lr_image = downscale_image(image, random_factors[0])\n",
    "    hr_image = downscale_image(image, random_factors[1])\n",
    "\n",
    "    lr_image = cv2.resize(lr_image, (export_image_dims[1], export_image_dims[0]))\n",
    "    hr_image = cv2.resize(hr_image, (export_image_dims[1], export_image_dims[0]))\n",
    "\n",
    "    return lr_image, hr_image\n",
    "\n",
    "\n",
    "def make_dataset(export_folder, export_image_dims, image_count=-1):\n",
    "    # grab up all the raw file paths\n",
    "    raw_images_folder = r\"H:\\my_files\\my_programs\\cat_upscaler\\datasets\\raw_cat_images\"\n",
    "    image_paths = [\n",
    "        os.path.join(raw_images_folder, f)\n",
    "        for f in os.listdir(raw_images_folder)\n",
    "        if os.path.isfile(os.path.join(raw_images_folder, f))\n",
    "    ]\n",
    "    random.shuffle(image_paths)\n",
    "    print(f\"there are {len(image_paths)} images in the folder\")\n",
    "\n",
    "    hr_folder = os.path.join(export_folder, \"hr\")\n",
    "    lr_folder = os.path.join(export_folder, \"lr\")\n",
    "\n",
    "    # remove any existing export folders\n",
    "    if os.path.exists(export_folder):\n",
    "        shutil.rmtree(export_folder)\n",
    "\n",
    "    # assure export folders exist\n",
    "    for folder in [export_folder, hr_folder, lr_folder]:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "    # handle cutting to size\n",
    "    if image_count != -1:\n",
    "        image_paths = (\n",
    "            random.sample(image_paths, image_count)\n",
    "            if len(image_paths) > image_count\n",
    "            else image_paths\n",
    "        )\n",
    "\n",
    "    # process each image into the lr and hr images, then save them\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        operation_start_time = time.time()\n",
    "        if image_count != -1 and i >= image_count:\n",
    "            break\n",
    "        lr_image, hr_image = make_datum(image_path, export_image_dims)\n",
    "        # show_images_side_by_side(lr_image, hr_image)\n",
    "        fn = f\"{i}.png\"\n",
    "        cv2.imwrite(os.path.join(hr_folder, fn), hr_image)\n",
    "        cv2.imwrite(os.path.join(lr_folder, fn), lr_image)\n",
    "        operation_time_taken = round((time.time() - operation_start_time),3)\n",
    "        if i % 10 == 0:print(f\"({i} / {len(image_paths)}) {operation_time_taken}s per operation\")\n",
    "    print('done')\n",
    "\n",
    "make_dataset(\n",
    "    r\"H:\\my_files\\my_programs\\cat_upscaler\\datasets\\cat_downscale_4_500_count\",\n",
    "    (2560, 2560),\n",
    "    image_count=500,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
